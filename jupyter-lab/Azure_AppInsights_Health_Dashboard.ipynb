{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ddc98c",
   "metadata": {},
   "source": [
    "# üè• Azure Application Insights - System Health & Performance Dashboard\n",
    "\n",
    "This notebook creates a comprehensive, interactive dashboard that displays the complete overall system health, performance metrics, and failure analysis from Azure Application Insights using Kusto Query Language (KQL).\n",
    "\n",
    "**Dashboard Features:**\n",
    "- üìä Overall Health Status Score\n",
    "- ‚ö° Performance Metrics (Response Times, Throughput)\n",
    "- ‚ùå Failure Analysis (Error Rates, Exceptions)\n",
    "- üìà Trend Analysis\n",
    "- üéØ Key Performance Indicators (KPIs)\n",
    "- üî¥üü°üü¢ Color-coded Status Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390dc9e0",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e39a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.monitor.query import LogsQueryClient\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44a835",
   "metadata": {},
   "source": [
    "## 2. Connect to Azure Application Insights\n",
    "\n",
    "Set your Azure credentials and Application Insights details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Configuration\n",
    "# Replace these with your actual Application Insights workspace ID\n",
    "WORKSPACE_ID = \"your-workspace-id\"  # e.g., \"12345678-1234-1234-1234-123456789012\"\n",
    "\n",
    "# Initialize Azure credentials (uses default authentication chain)\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = LogsQueryClient(credential)\n",
    "    print(\"‚úÖ Azure connection established successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Note: To use live data, configure WORKSPACE_ID and Azure credentials.\")\n",
    "    print(f\"    Error: {str(e)}\")\n",
    "    print(\"    For now, we'll use sample data for demonstration.\")\n",
    "    client = None\n",
    "\n",
    "# Time range for query\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(hours=24)  # Last 24 hours\n",
    "\n",
    "print(f\"üìÖ Query time range: {start_time} to {end_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daff886",
   "metadata": {},
   "source": [
    "## 3. Query Application Insights Data with KQL\n",
    "\n",
    "Execute comprehensive KQL queries to retrieve system health, performance, and failure metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cdcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_kql_query(kql_query):\n",
    "    \"\"\"Execute KQL query and return results as DataFrame\"\"\"\n",
    "    if client is None:\n",
    "        return None\n",
    "    try:\n",
    "        result = client.query_workspace(WORKSPACE_ID, kql_query)\n",
    "        df = pd.DataFrame(result.tables[0].rows, columns=[col.name for col in result.tables[0].columns])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# KQL Query 1: Overall System Health Metrics\n",
    "kql_health = \"\"\"\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    TotalRequests = count(),\n",
    "    SuccessfulRequests = countif(success == true),\n",
    "    FailedRequests = countif(success == false),\n",
    "    AverageResponseTime = avg(duration),\n",
    "    P95ResponseTime = percentile(duration, 95),\n",
    "    P99ResponseTime = percentile(duration, 99)\n",
    "| extend\n",
    "    SuccessRate = (SuccessfulRequests * 100.0) / TotalRequests,\n",
    "    FailureRate = (FailedRequests * 100.0) / TotalRequests\n",
    "\"\"\"\n",
    "\n",
    "# KQL Query 2: Exception and Error Analysis\n",
    "kql_exceptions = \"\"\"\n",
    "exceptions\n",
    "| where timestamp > ago(24h)\n",
    "| summarize \n",
    "    TotalExceptions = count(),\n",
    "    CriticalCount = countif(severityLevel == 1),\n",
    "    WarningCount = countif(severityLevel == 2),\n",
    "    InfoCount = countif(severityLevel == 3)\n",
    "| extend\n",
    "    CriticalPercentage = (CriticalCount * 100.0) / TotalExceptions,\n",
    "    WarningPercentage = (WarningCount * 100.0) / TotalExceptions\n",
    "\"\"\"\n",
    "\n",
    "# KQL Query 3: Performance by Operation\n",
    "kql_performance = \"\"\"\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    RequestCount = count(),\n",
    "    AvgDuration = avg(duration),\n",
    "    MaxDuration = max(duration),\n",
    "    SuccessCount = countif(success == true)\n",
    "    by name\n",
    "| extend\n",
    "    SuccessRate = (SuccessCount * 100.0) / RequestCount\n",
    "| order by AvgDuration desc\n",
    "| limit 10\n",
    "\"\"\"\n",
    "\n",
    "# KQL Query 4: Availability and Uptime\n",
    "kql_availability = \"\"\"\n",
    "availabilityResults\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    TestCount = count(),\n",
    "    PassedTests = countif(success == true),\n",
    "    FailedTests = countif(success == false)\n",
    "| extend\n",
    "    AvailabilityPercentage = (PassedTests * 100.0) / TestCount\n",
    "\"\"\"\n",
    "\n",
    "# KQL Query 5: Request Timeline (Hourly Trend)\n",
    "kql_timeline = \"\"\"\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    RequestCount = count(),\n",
    "    SuccessCount = countif(success == true),\n",
    "    FailureCount = countif(success == false),\n",
    "    AvgResponse = avg(duration)\n",
    "    by bin(timestamp, 1h)\n",
    "| order by timestamp asc\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìä KQL queries defined. Attempting to retrieve data...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute queries (or generate sample data if offline)\n",
    "if client is not None:\n",
    "    df_health = execute_kql_query(kql_health)\n",
    "    df_exceptions = execute_kql_query(kql_exceptions)\n",
    "    df_performance = execute_kql_query(kql_performance)\n",
    "    df_availability = execute_kql_query(kql_availability)\n",
    "    df_timeline = execute_kql_query(kql_timeline)\n",
    "else:\n",
    "    # Generate realistic sample data for demonstration\n",
    "    print(\"üìä Generating sample data for visualization...\\n\")\n",
    "    \n",
    "    # Sample Health Data\n",
    "    df_health = pd.DataFrame({\n",
    "        'TotalRequests': [15847],\n",
    "        'SuccessfulRequests': [15421],\n",
    "        'FailedRequests': [426],\n",
    "        'AverageResponseTime': [234.5],\n",
    "        'P95ResponseTime': [892.3],\n",
    "        'P99ResponseTime': [1245.7],\n",
    "        'SuccessRate': [97.31],\n",
    "        'FailureRate': [2.69]\n",
    "    })\n",
    "    \n",
    "    # Sample Exception Data\n",
    "    df_exceptions = pd.DataFrame({\n",
    "        'TotalExceptions': [148],\n",
    "        'CriticalCount': [12],\n",
    "        'WarningCount': [45],\n",
    "        'InfoCount': [91],\n",
    "        'CriticalPercentage': [8.11],\n",
    "        'WarningPercentage': [30.41]\n",
    "    })\n",
    "    \n",
    "    # Sample Performance Data\n",
    "    df_performance = pd.DataFrame({\n",
    "        'name': ['API/Orders/GetDetails', 'API/Users/Authenticate', 'API/Reports/Generate', \n",
    "                 'API/Data/Sync', 'API/Files/Upload', 'API/Dashboard/Load'],\n",
    "        'RequestCount': [2341, 3245, 1823, 4521, 1234, 2683],\n",
    "        'AvgDuration': [542.3, 234.1, 1823.5, 456.7, 2134.2, 789.3],\n",
    "        'MaxDuration': [3245.7, 1234.2, 8923.1, 2341.5, 9234.6, 4123.2],\n",
    "        'SuccessCount': [2312, 3198, 1745, 4423, 1167, 2589],\n",
    "        'SuccessRate': [98.76, 98.55, 95.73, 97.83, 94.56, 96.50]\n",
    "    })\n",
    "    \n",
    "    # Sample Availability Data\n",
    "    df_availability = pd.DataFrame({\n",
    "        'TestCount': [144],\n",
    "        'PassedTests': [142],\n",
    "        'FailedTests': [2],\n",
    "        'AvailabilityPercentage': [98.61]\n",
    "    })\n",
    "    \n",
    "    # Sample Timeline Data\n",
    "    hours = pd.date_range(end=datetime.utcnow(), periods=24, freq='H')\n",
    "    df_timeline = pd.DataFrame({\n",
    "        'timestamp': hours,\n",
    "        'RequestCount': np.random.randint(500, 1200, 24),\n",
    "        'SuccessCount': np.random.randint(480, 1180, 24),\n",
    "        'FailureCount': np.random.randint(10, 100, 24),\n",
    "        'AvgResponse': np.random.uniform(200, 400, 24)\n",
    "    })\n",
    "\n",
    "print(\"‚úÖ Data retrieved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e82cf5",
   "metadata": {},
   "source": [
    "## 4. Process and Aggregate Metrics\n",
    "\n",
    "Calculate comprehensive health scores and performance indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ff74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_health_score(success_rate, response_time, availability, exceptions):\n",
    "    \"\"\"\n",
    "    Calculate overall health score (0-100)\n",
    "    Weighted factors:\n",
    "    - Success Rate: 40%\n",
    "    - Response Time: 30%\n",
    "    - Availability: 20%\n",
    "    - Exceptions: 10%\n",
    "    \"\"\"\n",
    "    # Normalize success rate (already a percentage, max 100)\n",
    "    success_score = min(success_rate, 100)\n",
    "    \n",
    "    # Normalize response time (target < 500ms, worst case > 2000ms)\n",
    "    response_score = max(0, 100 - ((response_time - 200) / 18))\n",
    "    response_score = min(100, max(0, response_score))\n",
    "    \n",
    "    # Normalize availability (already a percentage)\n",
    "    availability_score = min(availability, 100)\n",
    "    \n",
    "    # Normalize exceptions (fewer is better)\n",
    "    exception_score = max(0, 100 - (exceptions * 2))\n",
    "    \n",
    "    # Calculate weighted health score\n",
    "    health_score = (\n",
    "        (success_score * 0.40) +\n",
    "        (response_score * 0.30) +\n",
    "        (availability_score * 0.20) +\n",
    "        (exception_score * 0.10)\n",
    "    )\n",
    "    \n",
    "    return min(100, max(0, health_score))\n",
    "\n",
    "def get_health_status(score):\n",
    "    \"\"\"Determine health status based on score\"\"\"\n",
    "    if score >= 95:\n",
    "        return \"üü¢ EXCELLENT\", \"green\"\n",
    "    elif score >= 85:\n",
    "        return \"üü¢ HEALTHY\", \"lightgreen\"\n",
    "    elif score >= 70:\n",
    "        return \"üü° WARNING\", \"yellow\"\n",
    "    elif score >= 50:\n",
    "        return \"üü† CONCERNING\", \"orange\"\n",
    "    else:\n",
    "        return \"üî¥ CRITICAL\", \"red\"\n",
    "\n",
    "# Extract metrics from dataframes\n",
    "health_data = df_health.iloc[0]\n",
    "exc_data = df_exceptions.iloc[0]\n",
    "avail_data = df_availability.iloc[0]\n",
    "\n",
    "success_rate = health_data['SuccessRate']\n",
    "avg_response = health_data['AverageResponseTime']\n",
    "availability = avail_data['AvailabilityPercentage']\n",
    "total_exceptions = exc_data['TotalExceptions']\n",
    "\n",
    "# Calculate overall health score\n",
    "overall_health_score = calculate_health_score(\n",
    "    success_rate,\n",
    "    avg_response,\n",
    "    availability,\n",
    "    total_exceptions / 100  # Normalize exception count\n",
    ")\n",
    "\n",
    "health_status, health_color = get_health_status(overall_health_score)\n",
    "\n",
    "# Performance metrics\n",
    "p95_response = health_data['P95ResponseTime']\n",
    "p99_response = health_data['P99ResponseTime']\n",
    "throughput = health_data['TotalRequests'] / 24  # requests per hour\n",
    "\n",
    "# Failure metrics\n",
    "failure_rate = health_data['FailureRate']\n",
    "critical_exceptions = exc_data['CriticalCount']\n",
    "warning_exceptions = exc_data['WarningCount']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  OVERALL SYSTEM HEALTH SCORE: {overall_health_score:.1f}/100 {health_status}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nüìä KEY PERFORMANCE INDICATORS:\")\n",
    "print(f\"  ‚Ä¢ Success Rate: {success_rate:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Average Response Time: {avg_response:.1f}ms\")\n",
    "print(f\"  ‚Ä¢ P95 Response Time: {p95_response:.1f}ms\")\n",
    "print(f\"  ‚Ä¢ P99 Response Time: {p99_response:.1f}ms\")\n",
    "print(f\"  ‚Ä¢ Availability: {availability:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Throughput: {throughput:.1f} req/hour\")\n",
    "print(f\"\\n‚ö†Ô∏è  FAILURE & ERROR METRICS:\")\n",
    "print(f\"  ‚Ä¢ Failure Rate: {failure_rate:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Total Exceptions: {int(total_exceptions)}\")\n",
    "print(f\"  ‚Ä¢ Critical Exceptions: {int(critical_exceptions)}\")\n",
    "print(f\"  ‚Ä¢ Warning Exceptions: {int(warning_exceptions)}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58857b",
   "metadata": {},
   "source": [
    "## 5. Create Comprehensive Health Dashboard Visualization\n",
    "\n",
    "Build an interactive, multi-component dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8deb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dashboard with multiple subplots\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=3,\n",
    "    subplot_titles=(\n",
    "        \"üè• Overall Health Status\",\n",
    "        \"‚ö° Success vs Failure Rate\",\n",
    "        \"üéØ Service Availability\",\n",
    "        \"üìà Response Time Distribution\",\n",
    "        \"üî¥ Exception Severity Breakdown\",\n",
    "        \"‚è±Ô∏è Response Time Percentiles\",\n",
    "        \"üìä Request Timeline (24h)\",\n",
    "        \"üöÄ Top Endpoints Performance\",\n",
    "        \"‚öôÔ∏è System Metrics Overview\"\n",
    "    ),\n",
    "    specs=[\n",
    "        [{\"type\": \"indicator\"}, {\"type\": \"pie\"}, {\"type\": \"indicator\"}],\n",
    "        [{\"type\": \"box\"}, {\"type\": \"pie\"}, {\"type\": \"bar\"}],\n",
    "        [{\"type\": \"scatter\"}, {\"type\": \"bar\"}, {\"type\": \"table\"}]\n",
    "    ],\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.10,\n",
    "    row_heights=[0.25, 0.35, 0.40]\n",
    ")\n",
    "\n",
    "# 1. Overall Health Status (Gauge Chart)\n",
    "fig.add_trace(\n",
    "    go.Indicator(\n",
    "        mode=\"gauge+number+delta\",\n",
    "        value=overall_health_score,\n",
    "        title={\"text\": \"Health Score\"},\n",
    "        domain={\"x\": [0, 1], \"y\": [0, 1]},\n",
    "        gauge={\n",
    "            \"axis\": {\"range\": [0, 100]},\n",
    "            \"bar\": {\"color\": health_color},\n",
    "            \"steps\": [\n",
    "                {\"range\": [0, 50], \"color\": \"rgba(255, 0, 0, 0.1)\"},\n",
    "                {\"range\": [50, 70], \"color\": \"rgba(255, 165, 0, 0.1)\"},\n",
    "                {\"range\": [70, 85], \"color\": \"rgba(255, 255, 0, 0.1)\"},\n",
    "                {\"range\": [85, 95], \"color\": \"rgba(144, 238, 144, 0.1)\"},\n",
    "                {\"range\": [95, 100], \"color\": \"rgba(0, 128, 0, 0.1)\"}\n",
    "            ],\n",
    "            \"threshold\": {\n",
    "                \"line\": {\"color\": \"red\", \"width\": 4},\n",
    "                \"thickness\": 0.75,\n",
    "                \"value\": 50\n",
    "            }\n",
    "        },\n",
    "        delta={\"reference\": 85}\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Success vs Failure Rate (Pie Chart)\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=[\"‚úÖ Successful\", \"‚ùå Failed\"],\n",
    "        values=[success_rate, failure_rate],\n",
    "        marker={\"colors\": [\"#2ecc71\", \"#e74c3c\"]},\n",
    "        hovertemplate=\"<b>%{label}</b><br>%{value:.2f}%<extra></extra>\",\n",
    "        textposition=\"inside\",\n",
    "        textinfo=\"label+percent\"\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Service Availability (Indicator)\n",
    "fig.add_trace(\n",
    "    go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=availability,\n",
    "        title={\"text\": \"Availability %\"},\n",
    "        domain={\"x\": [0, 1], \"y\": [0, 1]},\n",
    "        gauge={\n",
    "            \"axis\": {\"range\": [95, 100]},\n",
    "            \"bar\": {\"color\": \"#3498db\"},\n",
    "            \"steps\": [\n",
    "                {\"range\": [95, 97], \"color\": \"rgba(52, 152, 219, 0.1)\"},\n",
    "                {\"range\": [97, 99], \"color\": \"rgba(52, 152, 219, 0.2)\"},\n",
    "                {\"range\": [99, 100], \"color\": \"rgba(52, 152, 219, 0.3)\"}\n",
    "            ]\n",
    "        }\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "# 4. Response Time Distribution (Box Plot)\n",
    "response_times = [avg_response, p95_response, p99_response]\n",
    "fig.add_trace(\n",
    "    go.Box(y=response_times, name=\"Response Time (ms)\", \n",
    "           marker={\"color\": \"#9b59b6\"}, boxmean='sd'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 5. Exception Severity (Pie Chart)\n",
    "exception_colors = [\"#c0392b\", \"#f39c12\", \"#3498db\"]\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=[\"üî¥ Critical\", \"üü° Warning\", \"‚ÑπÔ∏è Info\"],\n",
    "        values=[critical_exceptions, warning_exceptions, exc_data['InfoCount']],\n",
    "        marker={\"colors\": exception_colors},\n",
    "        hovertemplate=\"<b>%{label}</b><br>Count: %{value}<extra></extra>\",\n",
    "        textinfo=\"label+value\"\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# 6. Response Time Percentiles (Bar Chart)\n",
    "percentile_labels = [\"Avg\", \"P95\", \"P99\"]\n",
    "percentile_values = [avg_response, p95_response, p99_response]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=percentile_labels,\n",
    "        y=percentile_values,\n",
    "        marker={\"color\": [\"#2ecc71\", \"#f39c12\", \"#e74c3c\"]},\n",
    "        text=[f\"{v:.0f}ms\" for v in percentile_values],\n",
    "        textposition=\"outside\",\n",
    "        hovertemplate=\"<b>%{x}</b><br>%{y:.1f}ms<extra></extra>\",\n",
    "        name=\"Response Time\"\n",
    "    ),\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "# 7. Request Timeline (Scatter/Line Chart)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_timeline['timestamp'],\n",
    "        y=df_timeline['RequestCount'],\n",
    "        mode='lines+markers',\n",
    "        name='Requests',\n",
    "        line={\"color\": \"#3498db\", \"width\": 3},\n",
    "        marker={\"size\": 6},\n",
    "        hovertemplate=\"<b>%{x}</b><br>Requests: %{y}<extra></extra>\",\n",
    "        fill='tozeroy'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# 8. Top Endpoints Performance (Horizontal Bar Chart)\n",
    "top_endpoints = df_performance.nlargest(6, 'RequestCount')\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=top_endpoints['name'],\n",
    "        x=top_endpoints['AvgDuration'],\n",
    "        orientation='h',\n",
    "        marker={\"color\": top_endpoints['SuccessRate'], \n",
    "                \"colorscale\": \"RdYlGn\", \"showscale\": False},\n",
    "        text=[f\"{v:.0f}ms\" for v in top_endpoints['AvgDuration']],\n",
    "        textposition=\"outside\",\n",
    "        hovertemplate=\"<b>%{y}</b><br>Avg: %{x:.0f}ms<extra></extra>\",\n",
    "        name=\"Avg Duration\"\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "# 9. System Metrics Summary Table\n",
    "table_data = {\n",
    "    \"Metric\": [\n",
    "        \"Total Requests\",\n",
    "        \"Success Rate\",\n",
    "        \"Failure Rate\",\n",
    "        \"Avg Response\",\n",
    "        \"P95 Response\",\n",
    "        \"Availability\",\n",
    "        \"Throughput\",\n",
    "        \"Exceptions\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{int(health_data['TotalRequests']):,}\",\n",
    "        f\"{success_rate:.2f}%\",\n",
    "        f\"{failure_rate:.2f}%\",\n",
    "        f\"{avg_response:.1f}ms\",\n",
    "        f\"{p95_response:.1f}ms\",\n",
    "        f\"{availability:.2f}%\",\n",
    "        f\"{throughput:.1f}/hr\",\n",
    "        f\"{int(total_exceptions)}\"\n",
    "    ],\n",
    "    \"Status\": [\n",
    "        \"‚úÖ\" if health_data['TotalRequests'] > 10000 else \"‚ö†Ô∏è\",\n",
    "        \"‚úÖ\" if success_rate > 95 else \"‚ö†Ô∏è\",\n",
    "        \"‚úÖ\" if failure_rate < 5 else \"‚ö†Ô∏è\",\n",
    "        \"‚úÖ\" if avg_response < 300 else \"‚ö†Ô∏è\",\n",
    "        \"‚úÖ\" if p95_response < 1000 else \"‚ö†Ô∏è\",\n",
    "        \"‚úÖ\" if availability > 99 else \"‚ö†Ô∏è\",\n",
    "        \"‚úÖ\" if throughput > 500 else \"‚ö†Ô∏è\",\n",
    "        \"‚úÖ\" if total_exceptions < 100 else \"‚ö†Ô∏è\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"<b>Metric</b>\", \"<b>Value</b>\", \"<b>Status</b>\"],\n",
    "            fill_color=\"#2c3e50\",\n",
    "            font=dict(color=\"white\", size=11),\n",
    "            height=25\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[table_data[\"Metric\"], table_data[\"Value\"], table_data[\"Status\"]],\n",
    "            fill_color=[\"#ecf0f1\", \"#ecf0f1\"],\n",
    "            font=dict(size=10),\n",
    "            height=25\n",
    "        )\n",
    "    ),\n",
    "    row=3, col=3\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        \"text\": \"<b>üè• Azure Application Insights - System Health & Performance Dashboard</b>\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"font\": {\"size\": 24, \"color\": \"#2c3e50\"}\n",
    "    },\n",
    "    showlegend=False,\n",
    "    height=1400,\n",
    "    width=1600,\n",
    "    template=\"plotly_white\",\n",
    "    font={\"family\": \"Arial, sans-serif\", \"size\": 10},\n",
    "    paper_bgcolor=\"#f8f9fa\",\n",
    "    plot_bgcolor=\"#ffffff\",\n",
    "    margin={\"l\": 50, \"r\": 50, \"t\": 100, \"b\": 50}\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#ecf0f1')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#ecf0f1')\n",
    "\n",
    "# Display the dashboard\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n‚úÖ Dashboard created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe5e93",
   "metadata": {},
   "source": [
    "## 6. Advanced Analytics - Deep Dive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed performance breakdown dashboard\n",
    "fig2 = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        \"üöÄ Endpoint Performance Comparison\",\n",
    "        \"üìä Request Distribution\",\n",
    "        \"‚è±Ô∏è Response Time by Endpoint\",\n",
    "        \"‚úÖ Success Rate Ranking\"\n",
    "    ),\n",
    "    specs=[\n",
    "        [{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "        [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]\n",
    "    ],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "# 1. Endpoint Requests Count\n",
    "fig2.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_performance['name'],\n",
    "        y=df_performance['RequestCount'],\n",
    "        marker={\"color\": \"#3498db\"},\n",
    "        text=df_performance['RequestCount'],\n",
    "        textposition=\"outside\",\n",
    "        hovertemplate=\"<b>%{x}</b><br>Requests: %{y:,.0f}<extra></extra>\",\n",
    "        name=\"Request Count\"\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Success Count vs Failed\n",
    "df_performance['FailedCount'] = df_performance['RequestCount'] - df_performance['SuccessCount']\n",
    "fig2.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_performance['name'],\n",
    "        y=df_performance['SuccessCount'],\n",
    "        marker={\"color\": \"#2ecc71\"},\n",
    "        name=\"‚úÖ Success\",\n",
    "        hovertemplate=\"<b>%{x}</b><br>Success: %{y:,.0f}<extra></extra>\"\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig2.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_performance['name'],\n",
    "        y=df_performance['FailedCount'],\n",
    "        marker={\"color\": \"#e74c3c\"},\n",
    "        name=\"‚ùå Failed\",\n",
    "        hovertemplate=\"<b>%{x}</b><br>Failed: %{y:,.0f}<extra></extra>\"\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Response Time Trend\n",
    "fig2.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_performance['name'],\n",
    "        y=df_performance['AvgDuration'],\n",
    "        mode='lines+markers',\n",
    "        name='Avg Duration',\n",
    "        line={\"color\": \"#f39c12\", \"width\": 3},\n",
    "        marker={\"size\": 10},\n",
    "        fill='tozeroy',\n",
    "        hovertemplate=\"<b>%{x}</b><br>Avg: %{y:.0f}ms<extra></extra>\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig2.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_performance['name'],\n",
    "        y=df_performance['MaxDuration'],\n",
    "        mode='markers',\n",
    "        name='Max Duration',\n",
    "        marker={\"size\": 8, \"color\": \"#e74c3c\"},\n",
    "        hovertemplate=\"<b>%{x}</b><br>Max: %{y:.0f}ms<extra></extra>\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Success Rate Ranking\n",
    "colors_success = ['#2ecc71' if x >= 95 else '#f39c12' if x >= 90 else '#e74c3c' \n",
    "                  for x in df_performance['SuccessRate']]\n",
    "fig2.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_performance['SuccessRate'],\n",
    "        y=df_performance['name'],\n",
    "        orientation='h',\n",
    "        marker={\"color\": colors_success},\n",
    "        text=[f\"{x:.1f}%\" for x in df_performance['SuccessRate']],\n",
    "        textposition=\"outside\",\n",
    "        hovertemplate=\"<b>%{y}</b><br>Success: %{x:.2f}%<extra></extra>\",\n",
    "        name=\"Success Rate\"\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig2.update_layout(\n",
    "    title={\n",
    "        \"text\": \"<b>üìä Detailed Endpoint Performance Analysis</b>\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"font\": {\"size\": 22, \"color\": \"#2c3e50\"}\n",
    "    },\n",
    "    showlegend=True,\n",
    "    height=900,\n",
    "    width=1600,\n",
    "    template=\"plotly_white\",\n",
    "    font={\"family\": \"Arial, sans-serif\", \"size\": 10},\n",
    "    paper_bgcolor=\"#f8f9fa\",\n",
    "    plot_bgcolor=\"#ffffff\",\n",
    "    barmode='stack'\n",
    ")\n",
    "\n",
    "fig2.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#ecf0f1')\n",
    "fig2.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#ecf0f1')\n",
    "\n",
    "fig2.show()\n",
    "\n",
    "print(\"‚úÖ Detailed performance analysis dashboard created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571229e3",
   "metadata": {},
   "source": [
    "## 7. Health Trend Analysis Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4af077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hourly health scores for trend analysis\n",
    "df_timeline['SuccessRate'] = (df_timeline['SuccessCount'] / df_timeline['RequestCount'] * 100).round(2)\n",
    "df_timeline['FailureRate'] = (df_timeline['FailureCount'] / df_timeline['RequestCount'] * 100).round(2)\n",
    "df_timeline['HourlyHealthScore'] = df_timeline.apply(\n",
    "    lambda row: calculate_health_score(\n",
    "        row['SuccessRate'],\n",
    "        row['AvgResponse'],\n",
    "        98.5,  # Average availability\n",
    "        row['FailureCount'] / 10\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create trend analysis dashboard\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"üìà System Health Score Trend (24h)\", \"üìä Requests & Errors Timeline\"),\n",
    "    specs=[[{\"secondary_y\": False}], [{\"secondary_y\": True}]],\n",
    "    vertical_spacing=0.15\n",
    ")\n",
    "\n",
    "# 1. Health Score Trend\n",
    "fig3.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_timeline['timestamp'],\n",
    "        y=df_timeline['HourlyHealthScore'],\n",
    "        mode='lines+markers',\n",
    "        name='Health Score',\n",
    "        line={\"color\": \"#3498db\", \"width\": 4},\n",
    "        marker={\"size\": 8},\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(52, 152, 219, 0.2)',\n",
    "        hovertemplate=\"<b>%{x|%H:%M}</b><br>Health: %{y:.1f}/100<extra></extra>\"\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add a reference line for good health\n",
    "fig3.add_hline(y=85, line_dash=\"dash\", line_color=\"#f39c12\", \n",
    "               annotation_text=\"Target: 85\", row=1, col=1)\n",
    "\n",
    "# 2. Requests Timeline\n",
    "fig3.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_timeline['timestamp'],\n",
    "        y=df_timeline['RequestCount'],\n",
    "        mode='lines',\n",
    "        name='Total Requests',\n",
    "        line={\"color\": \"#2ecc71\", \"width\": 3},\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(46, 204, 113, 0.2)',\n",
    "        hovertemplate=\"<b>%{x|%H:%M}</b><br>Requests: %{y:,.0f}<extra></extra>\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 3. Error Count (Secondary Axis)\n",
    "fig3.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_timeline['timestamp'],\n",
    "        y=df_timeline['FailureCount'],\n",
    "        mode='lines+markers',\n",
    "        name='Failures',\n",
    "        line={\"color\": \"#e74c3c\", \"width\": 3},\n",
    "        marker={\"size\": 6},\n",
    "        hovertemplate=\"<b>%{x|%H:%M}</b><br>Failures: %{y:,.0f}<extra></extra>\"\n",
    "    ),\n",
    "    row=2, col=1,\n",
    "    secondary_y=True\n",
    ")\n",
    "\n",
    "fig3.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "fig3.update_yaxes(title_text=\"Health Score (0-100)\", row=1, col=1)\n",
    "fig3.update_yaxes(title_text=\"Request Count\", row=2, col=1)\n",
    "fig3.update_yaxes(title_text=\"Failure Count\", row=2, col=1, secondary_y=True)\n",
    "\n",
    "fig3.update_layout(\n",
    "    title={\n",
    "        \"text\": \"<b>üìà System Health Trend Analysis - Last 24 Hours</b>\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"font\": {\"size\": 22, \"color\": \"#2c3e50\"}\n",
    "    },\n",
    "    showlegend=True,\n",
    "    height=800,\n",
    "    width=1400,\n",
    "    template=\"plotly_white\",\n",
    "    font={\"family\": \"Arial, sans-serif\", \"size\": 11},\n",
    "    paper_bgcolor=\"#f8f9fa\",\n",
    "    plot_bgcolor=\"#ffffff\",\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig3.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#ecf0f1')\n",
    "fig3.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#ecf0f1')\n",
    "\n",
    "fig3.show()\n",
    "\n",
    "print(\"‚úÖ Health trend analysis dashboard created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab9ba9",
   "metadata": {},
   "source": [
    "## 8. KQL Queries Reference\n",
    "\n",
    "Below are all the KQL queries used to generate this dashboard. Copy and paste into Azure Application Insights to run directly:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634d405",
   "metadata": {},
   "source": [
    "### Query 1: Overall System Health Metrics\n",
    "\n",
    "```kusto\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    TotalRequests = count(),\n",
    "    SuccessfulRequests = countif(success == true),\n",
    "    FailedRequests = countif(success == false),\n",
    "    AverageResponseTime = avg(duration),\n",
    "    P95ResponseTime = percentile(duration, 95),\n",
    "    P99ResponseTime = percentile(duration, 99)\n",
    "| extend\n",
    "    SuccessRate = (SuccessfulRequests * 100.0) / TotalRequests,\n",
    "    FailureRate = (FailedRequests * 100.0) / TotalRequests\n",
    "```\n",
    "\n",
    "### Query 2: Exception and Error Analysis\n",
    "\n",
    "```kusto\n",
    "exceptions\n",
    "| where timestamp > ago(24h)\n",
    "| summarize \n",
    "    TotalExceptions = count(),\n",
    "    CriticalCount = countif(severityLevel == 1),\n",
    "    WarningCount = countif(severityLevel == 2),\n",
    "    InfoCount = countif(severityLevel == 3)\n",
    "| extend\n",
    "    CriticalPercentage = (CriticalCount * 100.0) / TotalExceptions,\n",
    "    WarningPercentage = (WarningCount * 100.0) / TotalExceptions\n",
    "```\n",
    "\n",
    "### Query 3: Performance by Operation\n",
    "\n",
    "```kusto\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    RequestCount = count(),\n",
    "    AvgDuration = avg(duration),\n",
    "    MaxDuration = max(duration),\n",
    "    SuccessCount = countif(success == true)\n",
    "    by name\n",
    "| extend\n",
    "    SuccessRate = (SuccessCount * 100.0) / RequestCount\n",
    "| order by AvgDuration desc\n",
    "| limit 10\n",
    "```\n",
    "\n",
    "### Query 4: Service Availability\n",
    "\n",
    "```kusto\n",
    "availabilityResults\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    TestCount = count(),\n",
    "    PassedTests = countif(success == true),\n",
    "    FailedTests = countif(success == false)\n",
    "| extend\n",
    "    AvailabilityPercentage = (PassedTests * 100.0) / TestCount\n",
    "```\n",
    "\n",
    "### Query 5: Request Timeline (Hourly Trend)\n",
    "\n",
    "```kusto\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    RequestCount = count(),\n",
    "    SuccessCount = countif(success == true),\n",
    "    FailureCount = countif(success == false),\n",
    "    AvgResponse = avg(duration)\n",
    "    by bin(timestamp, 1h)\n",
    "| order by timestamp asc\n",
    "```\n",
    "\n",
    "### Query 6: Advanced - Request Performance Heatmap\n",
    "\n",
    "```kusto\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| extend bin_time = bin(timestamp, 1h), duration_bucket = case(\n",
    "    duration < 100, \"< 100ms\",\n",
    "    duration < 300, \"100-300ms\",\n",
    "    duration < 500, \"300-500ms\",\n",
    "    duration < 1000, \"500-1000ms\",\n",
    "    \">= 1000ms\"\n",
    ")\n",
    "| summarize count() by bin_time, duration_bucket, success\n",
    "| render columnchart\n",
    "```\n",
    "\n",
    "### Query 7: Error Analysis by Exception Type\n",
    "\n",
    "```kusto\n",
    "exceptions\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    ErrorCount = count(),\n",
    "    AffectedUsers = dcount(user_Id),\n",
    "    LastOccurrence = max(timestamp)\n",
    "    by type, severityLevel\n",
    "| order by ErrorCount desc\n",
    "```\n",
    "\n",
    "### Query 8: Custom Metric - System Health Score\n",
    "\n",
    "```kusto\n",
    "requests\n",
    "| where timestamp > ago(24h)\n",
    "| summarize\n",
    "    SuccessRate = (countif(success == true) * 100.0) / count(),\n",
    "    AvgResponse = avg(duration)\n",
    "    by bin(timestamp, 1h)\n",
    "| extend\n",
    "    HealthScore = case(\n",
    "        SuccessRate > 98 and AvgResponse < 300, 95,\n",
    "        SuccessRate > 95 and AvgResponse < 500, 85,\n",
    "        SuccessRate > 90 and AvgResponse < 1000, 70,\n",
    "        SuccessRate > 85, 50,\n",
    "        25\n",
    "    )\n",
    "| project timestamp, HealthScore, SuccessRate, AvgResponse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57e892",
   "metadata": {},
   "source": [
    "## 9. Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  üè• AZURE APPLICATION INSIGHTS - SYSTEM HEALTH REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÖ Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "print(f\"üìä Analysis Period: Last 24 hours\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*70}\")\n",
    "print(f\"  OVERALL HEALTH STATUS: {overall_health_score:.1f}/100 {health_status}\")\n",
    "print(f\"{'‚îÄ'*70}\")\n",
    "\n",
    "print(f\"\\n‚úÖ PERFORMANCE METRICS:\")\n",
    "print(f\"  ‚Ä¢ Total Requests: {int(health_data['TotalRequests']):,}\")\n",
    "print(f\"  ‚Ä¢ Successful Requests: {int(health_data['SuccessfulRequests']):,}\")\n",
    "print(f\"  ‚Ä¢ Failed Requests: {int(health_data['FailedRequests']):,}\")\n",
    "print(f\"  ‚Ä¢ Average Response Time: {avg_response:.1f}ms\")\n",
    "print(f\"  ‚Ä¢ P95 Response Time: {p95_response:.1f}ms\")\n",
    "print(f\"  ‚Ä¢ P99 Response Time: {p99_response:.1f}ms\")\n",
    "print(f\"  ‚Ä¢ Throughput: {throughput:.1f} requests/hour\")\n",
    "\n",
    "print(f\"\\nüéØ SUCCESS & AVAILABILITY:\")\n",
    "print(f\"  ‚Ä¢ Success Rate: {success_rate:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Failure Rate: {failure_rate:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Service Availability: {availability:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚ùå ERROR & EXCEPTION METRICS:\")\n",
    "print(f\"  ‚Ä¢ Total Exceptions: {int(total_exceptions)}\")\n",
    "print(f\"  ‚Ä¢ Critical Level Exceptions: {int(critical_exceptions)}\")\n",
    "print(f\"  ‚Ä¢ Warning Level Exceptions: {int(warning_exceptions)}\")\n",
    "print(f\"  ‚Ä¢ Info Level Messages: {int(exc_data['InfoCount'])}\")\n",
    "\n",
    "print(f\"\\nüìà TOP PERFORMING ENDPOINTS:\")\n",
    "for idx, row in df_performance.head(3).iterrows():\n",
    "    print(f\"  {idx+1}. {row['name']}\")\n",
    "    print(f\"     ‚îú‚îÄ Requests: {int(row['RequestCount']):,}\")\n",
    "    print(f\"     ‚îú‚îÄ Avg Response: {row['AvgDuration']:.0f}ms\")\n",
    "    print(f\"     ‚îî‚îÄ Success Rate: {row['SuccessRate']:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  LOWEST PERFORMING ENDPOINTS:\")\n",
    "for idx, row in df_performance.tail(2).iterrows():\n",
    "    status = \"üî¥\" if row['SuccessRate'] < 90 else \"üü°\"\n",
    "    print(f\"  {status} {row['name']}\")\n",
    "    print(f\"     ‚îú‚îÄ Avg Response: {row['AvgDuration']:.0f}ms\")\n",
    "    print(f\"     ‚îî‚îÄ Success Rate: {row['SuccessRate']:.2f}%\")\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "if success_rate >= 98:\n",
    "    print(f\"  ‚úÖ Excellent success rate! System is performing very well.\")\n",
    "elif success_rate >= 95:\n",
    "    print(f\"  üü¢ Good success rate. System performance is stable.\")\n",
    "else:\n",
    "    print(f\"  üü° Success rate below 95%. Investigate failures.\")\n",
    "\n",
    "if avg_response < 300:\n",
    "    print(f\"  ‚úÖ Response times are excellent. System is responsive.\")\n",
    "elif avg_response < 500:\n",
    "    print(f\"  üü° Response times are acceptable but could be optimized.\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  Response times are high. Consider optimization.\")\n",
    "\n",
    "if availability >= 99:\n",
    "    print(f\"  ‚úÖ High availability! SLA targets are met.\")\n",
    "elif availability >= 95:\n",
    "    print(f\"  üü° Availability is good but has room for improvement.\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  Availability is below SLA targets.\")\n",
    "\n",
    "if total_exceptions < 100:\n",
    "    print(f\"  ‚úÖ Exception count is low. System is stable.\")\n",
    "elif total_exceptions < 200:\n",
    "    print(f\"  üü° Moderate exception count. Monitor for patterns.\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  High exception count. Investigate root causes.\")\n",
    "\n",
    "print(f\"\\nüìã RECOMMENDATIONS:\")\n",
    "print(f\"  ‚Ä¢ Monitor endpoints with response times > 1000ms\")\n",
    "print(f\"  ‚Ä¢ Investigate exceptions with severity level = Critical\")\n",
    "print(f\"  ‚Ä¢ Optimize endpoints with success rate < 95%\")\n",
    "print(f\"  ‚Ä¢ Review performance trends in the hourly timeline\")\n",
    "print(f\"  ‚Ä¢ Set up alerts for health score < 85\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"  Report generated successfully!\")\n",
    "print(f\"=\"*70 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
