{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5381165919282511,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008968609865470852,
      "grad_norm": 2.051999092102051,
      "learning_rate": 0.0,
      "loss": 1.8416,
      "step": 1
    },
    {
      "epoch": 0.017937219730941704,
      "grad_norm": 2.057771682739258,
      "learning_rate": 4e-05,
      "loss": 1.8042,
      "step": 2
    },
    {
      "epoch": 0.026905829596412557,
      "grad_norm": 2.1038646697998047,
      "learning_rate": 8e-05,
      "loss": 1.8409,
      "step": 3
    },
    {
      "epoch": 0.03587443946188341,
      "grad_norm": 1.414911150932312,
      "learning_rate": 0.00012,
      "loss": 1.6641,
      "step": 4
    },
    {
      "epoch": 0.04484304932735426,
      "grad_norm": 0.8937432169914246,
      "learning_rate": 0.00016,
      "loss": 1.4708,
      "step": 5
    },
    {
      "epoch": 0.053811659192825115,
      "grad_norm": 0.7881600260734558,
      "learning_rate": 0.0002,
      "loss": 1.2777,
      "step": 6
    },
    {
      "epoch": 0.06278026905829596,
      "grad_norm": 0.7237719893455505,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.089,
      "step": 7
    },
    {
      "epoch": 0.07174887892376682,
      "grad_norm": 1.2025419473648071,
      "learning_rate": 0.00019272727272727274,
      "loss": 0.9306,
      "step": 8
    },
    {
      "epoch": 0.08071748878923767,
      "grad_norm": 0.8297043442726135,
      "learning_rate": 0.0001890909090909091,
      "loss": 0.8014,
      "step": 9
    },
    {
      "epoch": 0.08968609865470852,
      "grad_norm": 0.8433396220207214,
      "learning_rate": 0.00018545454545454545,
      "loss": 0.6877,
      "step": 10
    },
    {
      "epoch": 0.09865470852017937,
      "grad_norm": 0.9620969891548157,
      "learning_rate": 0.00018181818181818183,
      "loss": 0.6069,
      "step": 11
    },
    {
      "epoch": 0.10762331838565023,
      "grad_norm": 1.774942398071289,
      "learning_rate": 0.0001781818181818182,
      "loss": 0.5192,
      "step": 12
    },
    {
      "epoch": 0.11659192825112108,
      "grad_norm": 0.8352282047271729,
      "learning_rate": 0.00017454545454545454,
      "loss": 0.5683,
      "step": 13
    },
    {
      "epoch": 0.12556053811659193,
      "grad_norm": 0.5466001629829407,
      "learning_rate": 0.0001709090909090909,
      "loss": 0.4803,
      "step": 14
    },
    {
      "epoch": 0.13452914798206278,
      "grad_norm": 0.5570281147956848,
      "learning_rate": 0.00016727272727272728,
      "loss": 0.4451,
      "step": 15
    },
    {
      "epoch": 0.14349775784753363,
      "grad_norm": 0.5305250883102417,
      "learning_rate": 0.00016363636363636366,
      "loss": 0.4575,
      "step": 16
    },
    {
      "epoch": 0.15246636771300448,
      "grad_norm": 0.4667135775089264,
      "learning_rate": 0.00016,
      "loss": 0.442,
      "step": 17
    },
    {
      "epoch": 0.16143497757847533,
      "grad_norm": 0.48881837725639343,
      "learning_rate": 0.00015636363636363637,
      "loss": 0.444,
      "step": 18
    },
    {
      "epoch": 0.17040358744394618,
      "grad_norm": 0.5039688348770142,
      "learning_rate": 0.00015272727272727275,
      "loss": 0.4331,
      "step": 19
    },
    {
      "epoch": 0.17937219730941703,
      "grad_norm": 0.5547339916229248,
      "learning_rate": 0.0001490909090909091,
      "loss": 0.4391,
      "step": 20
    },
    {
      "epoch": 0.18834080717488788,
      "grad_norm": 0.4845161736011505,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.4142,
      "step": 21
    },
    {
      "epoch": 0.19730941704035873,
      "grad_norm": 0.5298084020614624,
      "learning_rate": 0.00014181818181818184,
      "loss": 0.4278,
      "step": 22
    },
    {
      "epoch": 0.2062780269058296,
      "grad_norm": 0.7597107291221619,
      "learning_rate": 0.0001381818181818182,
      "loss": 0.4093,
      "step": 23
    },
    {
      "epoch": 0.21524663677130046,
      "grad_norm": 0.46926558017730713,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.4075,
      "step": 24
    },
    {
      "epoch": 0.2242152466367713,
      "grad_norm": 0.47259971499443054,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.4025,
      "step": 25
    },
    {
      "epoch": 0.23318385650224216,
      "grad_norm": 0.49367019534111023,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.4105,
      "step": 26
    },
    {
      "epoch": 0.242152466367713,
      "grad_norm": 0.5734100341796875,
      "learning_rate": 0.00012363636363636364,
      "loss": 0.4044,
      "step": 27
    },
    {
      "epoch": 0.25112107623318386,
      "grad_norm": 0.6008526086807251,
      "learning_rate": 0.00012,
      "loss": 0.3898,
      "step": 28
    },
    {
      "epoch": 0.2600896860986547,
      "grad_norm": 0.5725759863853455,
      "learning_rate": 0.00011636363636363636,
      "loss": 0.3911,
      "step": 29
    },
    {
      "epoch": 0.26905829596412556,
      "grad_norm": 0.6068726181983948,
      "learning_rate": 0.00011272727272727272,
      "loss": 0.4133,
      "step": 30
    },
    {
      "epoch": 0.27802690582959644,
      "grad_norm": 0.6326501965522766,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.361,
      "step": 31
    },
    {
      "epoch": 0.28699551569506726,
      "grad_norm": 0.6488693952560425,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.366,
      "step": 32
    },
    {
      "epoch": 0.29596412556053814,
      "grad_norm": 0.7169935703277588,
      "learning_rate": 0.00010181818181818181,
      "loss": 0.3704,
      "step": 33
    },
    {
      "epoch": 0.30493273542600896,
      "grad_norm": 0.7301931381225586,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.3525,
      "step": 34
    },
    {
      "epoch": 0.31390134529147984,
      "grad_norm": 0.7989848852157593,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.353,
      "step": 35
    },
    {
      "epoch": 0.32286995515695066,
      "grad_norm": 0.7698227763175964,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.3409,
      "step": 36
    },
    {
      "epoch": 0.33183856502242154,
      "grad_norm": 0.5637306571006775,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.3246,
      "step": 37
    },
    {
      "epoch": 0.34080717488789236,
      "grad_norm": 0.44500112533569336,
      "learning_rate": 8.363636363636364e-05,
      "loss": 0.3396,
      "step": 38
    },
    {
      "epoch": 0.34977578475336324,
      "grad_norm": 0.40925928950309753,
      "learning_rate": 8e-05,
      "loss": 0.3291,
      "step": 39
    },
    {
      "epoch": 0.35874439461883406,
      "grad_norm": 0.4356994330883026,
      "learning_rate": 7.636363636363637e-05,
      "loss": 0.3558,
      "step": 40
    },
    {
      "epoch": 0.36771300448430494,
      "grad_norm": 0.4900030195713043,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.3657,
      "step": 41
    },
    {
      "epoch": 0.37668161434977576,
      "grad_norm": 0.4946266710758209,
      "learning_rate": 6.90909090909091e-05,
      "loss": 0.3506,
      "step": 42
    },
    {
      "epoch": 0.38565022421524664,
      "grad_norm": 0.44961872696876526,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.3203,
      "step": 43
    },
    {
      "epoch": 0.39461883408071746,
      "grad_norm": 0.5376009941101074,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.3323,
      "step": 44
    },
    {
      "epoch": 0.40358744394618834,
      "grad_norm": 0.5203960537910461,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.2962,
      "step": 45
    },
    {
      "epoch": 0.4125560538116592,
      "grad_norm": 0.5539760589599609,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.314,
      "step": 46
    },
    {
      "epoch": 0.42152466367713004,
      "grad_norm": 0.6053164005279541,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.2973,
      "step": 47
    },
    {
      "epoch": 0.4304932735426009,
      "grad_norm": 0.6315389275550842,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 0.3078,
      "step": 48
    },
    {
      "epoch": 0.43946188340807174,
      "grad_norm": 0.6592078804969788,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.2929,
      "step": 49
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 0.6807069182395935,
      "learning_rate": 4e-05,
      "loss": 0.3167,
      "step": 50
    },
    {
      "epoch": 0.45739910313901344,
      "grad_norm": 0.6619849801063538,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.3085,
      "step": 51
    },
    {
      "epoch": 0.4663677130044843,
      "grad_norm": 0.7021230459213257,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.2886,
      "step": 52
    },
    {
      "epoch": 0.47533632286995514,
      "grad_norm": 0.6835730075836182,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.3237,
      "step": 53
    },
    {
      "epoch": 0.484304932735426,
      "grad_norm": 0.6544316411018372,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.279,
      "step": 54
    },
    {
      "epoch": 0.49327354260089684,
      "grad_norm": 0.6176652908325195,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.3198,
      "step": 55
    },
    {
      "epoch": 0.5022421524663677,
      "grad_norm": 0.5250217914581299,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.2805,
      "step": 56
    },
    {
      "epoch": 0.5112107623318386,
      "grad_norm": 0.558679461479187,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.2881,
      "step": 57
    },
    {
      "epoch": 0.5201793721973094,
      "grad_norm": 0.5868430733680725,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.3041,
      "step": 58
    },
    {
      "epoch": 0.5291479820627802,
      "grad_norm": 0.5362533926963806,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.29,
      "step": 59
    },
    {
      "epoch": 0.5381165919282511,
      "grad_norm": 0.5141139030456543,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.2839,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4080108372344832.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
