# AI Code Review Docker Compose Environment Configuration
# Copy this to .env and update with your actual values

# ==============================================
# AI Code Review Server Configuration
# ==============================================

# GitLab Configuration
# Your GitLab instance URL (without trailing slash)
GITLAB_URL=https://gitlab.example.com

# Your GitLab Personal Access Token
# Create one at: GitLab Settings > Access Tokens
# Required scopes: api, read_api, read_repository
GITLAB_PAT=glpat-xxxxxxxxxxxxxxxxxxxx

# Ollama Configuration
# Ollama API endpoint (default for local installation)
OLLAMA_URL=http://localhost:11434

# AI model to use for code review
# Popular options: llama2, llama3, codellama, mistral
OLLAMA_MODEL=llama2

# Context window size for the AI model
# Adjust based on your model's capabilities
# Default is 6122 for llama2, 15122 for larger models like gemma
OLLAMA_NUM_CTX=6122

# Review Configuration (Optional)
# Name and email for the AI reviewer
REVIEWER_NAME=AI Code Reviewer
REVIEWER_EMAIL=ai-reviewer@example.com

# ==============================================
# Telegram Watcher Configuration
# ==============================================

# Telegram Bot Configuration
# Get your bot token from @BotFather on Telegram
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Telegram Chat ID (group or private chat)
# Use @userinfobot to get your chat ID, or for groups use @chatinfo_bot
TELEGRAM_CHAT_ID=-1001234567890

# Optional: Thread ID for filtering messages in threaded conversations
# If not specified, all messages from the chat will be monitored
# To get thread ID, enable "Show Message IDs" in Telegram and check message_thread_id
TELEGRAM_THREAD_ID=

# Review API URL - points to the ai-code-review-server service
# Note: Uses Docker service name for internal communication
REVIEW_API_URL=http://ai-code-review-server:8000/review
